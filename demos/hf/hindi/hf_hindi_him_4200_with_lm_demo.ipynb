{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hf_hindi_him_4200_with_lm_demo",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUR_s3tt_IJF"
      },
      "source": [
        "# Vakyansh + Hugging Face : Hindi Speech To text Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQCiOn_9_ZeI"
      },
      "source": [
        "## Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_UDaMuH_GnL"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!apt-get -y install sox ffmpeg\n",
        "!pip install transformers --upgrade \n",
        "!pip install ffmpeg-python sox\n",
        "\n",
        "!wget https://raw.githubusercontent.com/harveenchadha/bol/main/demos/colab/record.py\n",
        "\n",
        "!pip install pyctcdecode\n",
        "!pip install https://github.com/kpu/kenlm/archive/master.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ikp7WVluBacM"
      },
      "source": [
        "## Load Hindi Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ5rnYAt_rB1"
      },
      "source": [
        "import soundfile as sf\n",
        "import torch\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, Wav2Vec2ProcessorWithLM, AutoModelForCTC\n",
        "\n",
        "def load_model():\n",
        "    # load pretrained model\n",
        "    processor_with_lm = Wav2Vec2ProcessorWithLM.from_pretrained(\"Harveenchadha/vakyansh-wav2vec2-hindi-him-4200\")\n",
        "    processor = Wav2Vec2Processor.from_pretrained(\"Harveenchadha/vakyansh-wav2vec2-hindi-him-4200\")\n",
        "    model = AutoModelForCTC.from_pretrained(\"Harveenchadha/vakyansh-wav2vec2-hindi-him-4200\")\n",
        "    return processor_with_lm, processor, model\n",
        "\n",
        "processor_with_lm, processor, model = load_model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT5eskX5KqEZ"
      },
      "source": [
        "def parse_transcription(wav_file, use_lm=False):\n",
        "    # load audio    \n",
        "    audio_input, sample_rate = sf.read(wav_file)\n",
        "\n",
        "    # pad input values and return pt tensor\n",
        "    input_values = processor(audio_input, sampling_rate=16_000, return_tensors=\"pt\").input_values\n",
        "\n",
        "    # INFERENCE\n",
        "    # retrieve logits & take argmax\n",
        "     #.cpu()\n",
        "    #predicted_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "    # transcribe\n",
        "    #transcription = processor.decode(predicted_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    #transcription = processor.decode(logits)\n",
        "    if use_lm: \n",
        "        with torch.no_grad():\n",
        "            logits = model(input_values).logits.cpu().detach().numpy()[0]            \n",
        "        transcription = processor_with_lm.decode(logits).text\n",
        "        return transcription.replace('<s>','')\n",
        "    else:\n",
        "        logits = model(input_values).logits\n",
        "        predicted_ids = torch.argmax(logits, dim=-1)\n",
        "        transcription = processor.decode(predicted_ids[0], skip_special_tokens=True)\n",
        "        \n",
        "        return transcription"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6a1YbhPAXY0"
      },
      "source": [
        "## Record file using colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irfbRvhbAVs8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "0b35aaf4-bd50-4d9c-ff3e-db5530c9456f"
      },
      "source": [
        "from record import record_audio\n",
        "\n",
        "record_audio('test')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<script>\n",
              "var recordButton = document.createElement(\"BUTTON\");\n",
              "recordButton.appendChild(\n",
              "  document.createTextNode(\"Press to start recording\")\n",
              ");\n",
              "restyleButtonBeforeRecording();\n",
              "\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "my_div.appendChild(recordButton);\n",
              "\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "\n",
              "function restyleButtonBeforeRecording() {\n",
              "  recordButton.style.width = '270px';\n",
              "  recordButton.style.height = '90';\n",
              "  recordButton.style.padding = '25px';\n",
              "  recordButton.style.backgroundColor = '#4CAF50';\n",
              "  recordButton.style.fontSize = '18px';\n",
              "}\n",
              "\n",
              "function restyleButtonForRecording() {\n",
              "  recordButton.style.backgroundColor = '#008CBA';\n",
              "  recordButton.innerText = \"Recording... press to stop\";\n",
              "}\n",
              "\n",
              "function restyleButtonForSaving() {\n",
              "  recordButton.style.backgroundColor = '#b34d4d';\n",
              "  recordButton.innerText = \"Saving... please wait!\"\n",
              "}\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {\n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data);\n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      restyleButtonForSaving();\n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "  recordButton.onclick = () => {\n",
              "    restyleButtonForRecording();\n",
              "    recordButton.onclick = () => {\n",
              "      toggleRecording();\n",
              "      sleep(2000).then(() => {\n",
              "        // wait 2000ms for the data to be available...\n",
              "        // ideally this should use something like await...\n",
              "        // console.log(\"Inside data:\" + base64data)\n",
              "        resolve(base64data.toString());\n",
              "      });\n",
              "    };\n",
              "    navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "  };\n",
              "});\n",
              "\n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHiDi3a0JKNk"
      },
      "source": [
        "## Run Model on recorded file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIccgORyCm0S"
      },
      "source": [
        "output_with_lm = parse_transcription('test.wav', True)\n",
        "output = parse_transcription('test.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output, output_with_lm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJltCRxAK1dc",
        "outputId": "86c90b2c-f476-43eb-9c95-280aec3f89fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('और सुनाये क्या हलचाल है', 'और्सुना  ये क्या हलचल है ')"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1nESsTGkJZVY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}