{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech_Translation_Hindi",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMd3gN5x6owrOjx0Wqs2ZZl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harveenchadha/bol/blob/main/demos/gr/hindi/Speech_ASR_plus_Translation_Hindi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7dlRI1DA-7L"
      },
      "source": [
        "%%capture\n",
        "!pip install gradio\n",
        "!pip install transformers torchaudio\n",
        "!apt-get install sox\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr5M73K7O9-b"
      },
      "source": [
        "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
        "\n",
        "model_translate = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
        "tokenizer_translate = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n",
        "inlang='hi'\n",
        "outlang='en'\n",
        "tokenizer_translate.src_lang = inlang\n",
        "\n",
        "def translate(text):    \n",
        "\n",
        "    encoded_hi = tokenizer_translate(text, return_tensors=\"pt\")\n",
        "    generated_tokens = model_translate.generate(**encoded_hi, forced_bos_token_id=tokenizer_translate.get_lang_id(outlang))\n",
        "    return tokenizer_translate.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_RcZlMtD91P"
      },
      "source": [
        "import soundfile as sf\n",
        "import torch\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import argparse\n",
        "from glob import glob\n",
        "import torchaudio\n",
        "import subprocess\n",
        "import gradio as gr\n",
        "\n",
        "resampler = torchaudio.transforms.Resample(48_000, 16_000)\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"Harveenchadha/vakyansh-wav2vec2-hindi-him-4200\")\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"Harveenchadha/vakyansh-wav2vec2-hindi-him-4200\")\n",
        "\n",
        "\n",
        "def get_filename(wav_file):\n",
        "    filename_local = wav_file.split('/')[-1][:-4]\n",
        "    filename_new = '/tmp/'+filename_local+'_16.wav'    \n",
        "    subprocess.call([\"sox {} -r {} -b 16 -c 1 {}\".format(wav_file, str(16000), filename_new)], shell=True)\n",
        "    return filename_new\n",
        "\n",
        "def parse_transcription(wav_file):\n",
        "    # load pretrained model\n",
        "    \n",
        "    # load audio\n",
        "\n",
        "    wav_file = get_filename(wav_file.name)\n",
        "    audio_input, sample_rate = sf.read(wav_file)\n",
        "    #test_file = resampler(test_file[0])\n",
        "\n",
        "    # pad input values and return pt tensor\n",
        "    input_values = processor(audio_input, sampling_rate=16_000, return_tensors=\"pt\").input_values\n",
        "\n",
        "    # INFERENCE\n",
        "    # retrieve logits & take argmax\n",
        "    logits = model(input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "    # transcribe\n",
        "    transcription = processor.decode(predicted_ids[0], skip_special_tokens=True)\n",
        "    return transcription, translate(transcription)\n",
        "    #return transcription"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79UvmG93PCIQ"
      },
      "source": [
        "from gradio.mix import Parallel, Series"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMKzhMRVCkJd",
        "outputId": "264713ad-16a5-486e-8fa9-514523e165f3"
      },
      "source": [
        "input = gr.inputs.Audio(source=\"microphone\", type=\"file\", label=\"Please speak into the microphone\") \n",
        "output1 = gr.outputs.Textbox(label=\"Hindi Output from ASR\")\n",
        "output2 = gr.outputs.Textbox(label=\"English Translated Output\")\n",
        "\n",
        "\n",
        "gr.Interface(parse_transcription, inputs = input,  outputs=[output1, output2], analytics_enabled=False, \n",
        "                                                                            show_tips=False, \n",
        "                                                                            theme='huggingface',\n",
        "                                                                            layout='vertical',\n",
        "                                                                            title=\"Vakyansh: Speech To text for Indic Languages\",\n",
        "                                                                            description=\"This is a live demo for Speech to Text and Speech Translation. <br> Models used: wav2vec2 + m2m100\").launch( inline=False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Your interface requires microphone or webcam permissions - this may cause issues in Colab. Use the External URL in case of issues.\n",
            "This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted (NEW!)\n",
            "Running on External URL: https://56367.gradio.app\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Flask 'gradio.networking'>,\n",
              " 'http://127.0.0.1:7861/',\n",
              " 'https://56367.gradio.app')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq7UvfRvQC-b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}